{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Mining of Evaluation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xmltodict\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from imageio import imread\n",
    "\n",
    "DATA_PATH_STR = 'data/ILSVRC2015-VID-Curation/Data/VID/'\n",
    "TRAIN_STATS_PKL = 'dataset/imagenetvid/train_data_stats.pkl'\n",
    "VAL_STATS_PKL = 'dataset/imagenetvid/val_data_stats.pkl'\n",
    "SUBDIR_MAP = {'ILSVRC2015_VID_train_0000': 'a',\n",
    "            'ILSVRC2015_VID_train_0001': 'b',\n",
    "            'ILSVRC2015_VID_train_0002': 'c',\n",
    "            'ILSVRC2015_VID_train_0003': 'd',\n",
    "            '': 'e'}\n",
    "\n",
    "TRAIN_EVAL_SET_PKL = 'dataset/imagenetvid/train_eval_set.pkl'\n",
    "TRAIN_EVAL_STATS_PKL = 'dataset/imagenetvid/train_eval_stats.pkl'\n",
    "VAL_EVAL_SET_PKL = 'dataset/imagenetvid/val_eval_set.pkl'\n",
    "VAL_EVAL_STATS_PKL = 'dataset/imagenetvid/val_eval_stats.pkl'\n",
    "\n",
    "\n",
    "\n",
    "def make_validation_pickle():\n",
    "    val_eval_dataset, stats = [], Counter()\n",
    "    output = open(VAL_EVAL_SET_PKL, 'wb')\n",
    "    snippets = _get_snippets_dict(training=False)\n",
    "\n",
    "    # For each random multiobject video snippets\n",
    "    for video_snippet, _ in snippets['multiple_bboxes']:\n",
    "        # Choose a random frame\n",
    "        frame_annotation1 = _get_random_frame_annotation(video_snippet)\n",
    "\n",
    "        # Choose a random, non-occluded object in the image and call it anchor\n",
    "        anchor = _get_random_object_annotation(frame_annotation1, allow_occluded=False)\n",
    "        if anchor == None: continue\n",
    "        trackid = anchor['trackid']\n",
    "        # (Put the object class in a dictionary for stats)\n",
    "        stats[anchor['name']] += 1\n",
    "\n",
    "        found_positive = False\n",
    "        timeout = 100\n",
    "        while not found_positive and timeout > 0:\n",
    "            timeout -= 1\n",
    "            # Find a second frame\n",
    "            frame_annotation2 = _get_random_frame_annotation(video_snippet)\n",
    "            while frame_annotation1['filename'] == frame_annotation2['filename']:\n",
    "                frame_annotation2 = _get_random_frame_annotation(video_snippet)\n",
    "\n",
    "            # Find the same object in this frame and verify it's not occluded\n",
    "            positive = _get_object(frame_annotation2, trackid)\n",
    "            if positive == None: continue\n",
    "            # (if it is, repeat the last step until we find a good frame)\n",
    "            if positive['occluded'] == '0':\n",
    "                found_positive = True\n",
    "        if timeout == 0 or found_positive == False: continue\n",
    "\n",
    "        # Store all the objects of the last frame in a list\n",
    "        all_objects = _get_all_objects(frame_annotation2)\n",
    "        if len(all_objects) < 3: continue\n",
    "        # (Put the object class in a dictionary for stats)\n",
    "        for o in all_objects: stats[o['name']] += 1\n",
    "\n",
    "        # Label the first object and the same one from the list\n",
    "        # as 0, and the rest as 1\n",
    "        zero_if_equal_one_otherwise = lambda o: 0 if o['trackid'] == trackid else 1\n",
    "        labels = [0] + [zero_if_equal_one_otherwise(o) for o in all_objects]\n",
    "\n",
    "        # Prepare batch\n",
    "        images = [_get_framepath(frame_annotation1, trackid, training=False)] + \\\n",
    "          [_get_framepath(frame_annotation2, o['trackid'], training=False) for o in all_objects]\n",
    "        batch = (images, labels)\n",
    "\n",
    "        # Put this batch into the pickle\n",
    "        pickle.dump(batch, output, -1)\n",
    "\n",
    "    # Store the metadata into another pickle\n",
    "    output.close()\n",
    "    output = open(VAL_EVAL_STATS_PKL, 'wb')\n",
    "    pickle.dump(stats, output, -1)\n",
    "    output.close()\n",
    "\n",
    "\n",
    "def make_training_eval_pickle():\n",
    "    training_eval_dataset, stats = [], Counter()\n",
    "    output = open(TRAIN_EVAL_SET_PKL, 'wb')\n",
    "    snippets = _get_snippets_dict(training=True)\n",
    "\n",
    "    # For each random multiobject video snippets\n",
    "    for video_snippet, _ in snippets['multiple_bboxes']:\n",
    "        # Choose a random frame\n",
    "        frame_annotation1 = _get_random_frame_annotation(video_snippet)\n",
    "\n",
    "        # Choose a random, non-occluded object in the image and call it anchor\n",
    "        anchor = _get_random_object_annotation(frame_annotation1, allow_occluded=False)\n",
    "        if anchor == None: continue\n",
    "        trackid = anchor['trackid']\n",
    "        # (Put the object class in a dictionary for stats)\n",
    "        stats[anchor['name']] += 1\n",
    "\n",
    "        found_positive = False\n",
    "        timeout = 100\n",
    "        while not found_positive and timeout > 0:\n",
    "            timeout -= 1\n",
    "            # Find a second frame\n",
    "            frame_annotation2 = _get_random_frame_annotation(video_snippet)\n",
    "            while frame_annotation1['filename'] == frame_annotation2['filename']:\n",
    "                frame_annotation2 = _get_random_frame_annotation(video_snippet)\n",
    "\n",
    "            # Find the same object in this frame and verify it's not occluded\n",
    "            positive = _get_object(frame_annotation2, trackid)\n",
    "            if positive == None: continue\n",
    "            # (if it is, repeat the last step until we find a good frame)\n",
    "            if positive['occluded'] == '0':\n",
    "                found_positive = True\n",
    "        if timeout == 0 or found_positive == False: continue\n",
    "\n",
    "        # Store all the objects of the last frame in a list\n",
    "        all_objects = _get_all_objects(frame_annotation2)\n",
    "        if len(all_objects) < 3: continue\n",
    "        # (Put the object class in a dictionary for stats)\n",
    "        for o in all_objects: stats[o['name']] += 1\n",
    "\n",
    "        # Label the first object and the same one from the list\n",
    "        # as 0, and the rest as 1\n",
    "        zero_if_equal_one_otherwise = lambda o: 0 if o['trackid'] == trackid else 1\n",
    "        labels = [0] + [zero_if_equal_one_otherwise(o) for o in all_objects]\n",
    "\n",
    "        # Prepare batch\n",
    "        images = [_get_framepath(frame_annotation1, trackid, training=True)] + \\\n",
    "          [_get_framepath(frame_annotation2, o['trackid'], training=True) for o in all_objects]\n",
    "        batch = (images, labels)\n",
    "\n",
    "        # Put this batch into the pickle\n",
    "        pickle.dump(batch, output, -1)\n",
    "\n",
    "    # Store the metadata into another pickle\n",
    "    output.close()\n",
    "    output2 = open(TRAIN_EVAL_STATS_PKL, 'wb')\n",
    "    pickle.dump(stats, output2, -1)\n",
    "    output2.close()\n",
    "\n",
    "\n",
    "def _get_snippets_dict(training=True):\n",
    "    \"\"\"\n",
    "    Returns a structure that contains the video snippets categorized by\n",
    "    'missing_bbox', 'single_bboxes', 'multiple_bboxes', and 'all'.\n",
    "    \"\"\"\n",
    "    if training:\n",
    "        pkl_file = open(TRAIN_STATS_PKL, 'rb')\n",
    "        print(\"Loading training pickle...\")\n",
    "    else:\n",
    "        pkl_file = open(VAL_STATS_PKL, 'rb')\n",
    "        print(\"Loading validation pickle...\")\n",
    "\n",
    "    stats = pickle.load(pkl_file)\n",
    "    paths = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def _get_random_frame_annotation(snippet_path):\n",
    "    frame_files = os.listdir(snippet_path)\n",
    "    random.shuffle(frame_files)\n",
    "    for file in frame_files:\n",
    "        if file[-3:] != 'xml': continue\n",
    "        annotation_path = os.path.join(snippet_path, file)\n",
    "        return _get_annotation(annotation_path)\n",
    "\n",
    "\n",
    "def _get_pair_of_frames(snippet_path):\n",
    "    frames = [_get_random_frame_annotation(snippet_path) for _ in range(2)]\n",
    "    order_by_time = lambda f: int(f['filename'])\n",
    "    return tuple(sorted(frames, key=order_by_time))\n",
    "\n",
    "\n",
    "def _get_random_object_annotation(annotation, allow_occluded=True):\n",
    "    if 'object' in annotation:\n",
    "        obj = annotation['object']\n",
    "        if type(obj) == list and len(obj) > 0:\n",
    "            # multiple objects\n",
    "            random.shuffle(obj)\n",
    "            for o in obj:\n",
    "                if allow_occluded or o['occluded'] == '0':\n",
    "                    return o\n",
    "        else:\n",
    "            # single object\n",
    "            if allow_occluded or obj['occluded'] == '0':\n",
    "                return obj\n",
    "\n",
    "\n",
    "def _get_all_objects(annotation):\n",
    "    all_objects = []\n",
    "    if 'object' in annotation:\n",
    "        obj = annotation['object']\n",
    "        if type(obj) == list and len(obj) > 0:\n",
    "            # multiple objects\n",
    "            all_objects = obj\n",
    "        else:\n",
    "            # single object\n",
    "            all_objects.append(obj)\n",
    "    return all_objects\n",
    "\n",
    "\n",
    "def _get_annotation(annotation_path):\n",
    "    with open(annotation_path) as file:\n",
    "        xmlobj = xmltodict.parse(file.read())\n",
    "    annotation = xmlobj['annotation']\n",
    "    return annotation\n",
    "\n",
    "\n",
    "def _get_object(annotation, trackid):\n",
    "    if 'object' in annotation:\n",
    "        obj = annotation['object']\n",
    "        if type(obj) == list and len(obj) > 0:\n",
    "            # multiple objects\n",
    "            for o in obj:\n",
    "                if o['trackid'] == trackid:\n",
    "                    return o\n",
    "        else:\n",
    "            # single object\n",
    "            if obj['trackid'] == trackid:\n",
    "                return obj\n",
    "\n",
    "\n",
    "def _get_framepath(annotation, track_id, training=True):\n",
    "    \"\"\"Assumes track_id is a string and not an int.\"\"\"\n",
    "    def _get_full_snippetpath(snippet_path):\n",
    "        return os.path.join(DATA_PATH_STR, 'train', snippet_path)\n",
    "    \n",
    "    if training:\n",
    "        folder1, folder2 = annotation[\"folder\"].split('/')\n",
    "        snippet_path = os.path.join(SUBDIR_MAP[folder1], folder2)\n",
    "    else:\n",
    "        snippet_path = 'e/' + annotation[\"folder\"]\n",
    "    full_snippet_path = _get_full_snippetpath(snippet_path)\n",
    "\n",
    "    if len(track_id) == 1:\n",
    "        track_id = \"0\" + track_id\n",
    "\n",
    "    filename = annotation[\"filename\"]\n",
    "    real_filename = filename + \".\" + track_id + \".crop.x.jpg\"\n",
    "\n",
    "    return os.path.join(full_snippet_path, real_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_training_eval_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top(path):\n",
    "    pkl_file = open(path, 'rb')\n",
    "    print(pickle.load(pkl_file))\n",
    "    pkl_file.close()\n",
    "\n",
    "print_top(TRAIN_EVAL_SET_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pkl_file = open(TRAIN_EVAL_STATS_PKL, 'rb')\n",
    "stats = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "counts = {}\n",
    "i = 0\n",
    "for k, v in stats.items():\n",
    "    counts[i] = v\n",
    "    i += 1\n",
    "    \n",
    "assert len(counts) == 30, 'missing some class!'\n",
    "\n",
    "labels, values = zip(*counts.items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_validation_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top(VAL_EVAL_SET_PKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pkl_file = open(VAL_EVAL_STATS_PKL, 'rb')\n",
    "stats = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "counts = {}\n",
    "i = 0\n",
    "for k, v in stats.items():\n",
    "    counts[i] = v\n",
    "    i += 1\n",
    "    \n",
    "if len(counts) < 30:\n",
    "    print('missing some class!')\n",
    "\n",
    "labels, values = zip(*counts.items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.5, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
